/**
 * @file alloc.dox
 * @brief Memory Allocator Documentation
 * 
 * This file contains detailed documentation for the high-performance memory allocator
 * including AllocTable, allocation strategies, and performance characteristics.
 */

/**
 * @defgroup Allocator Memory Allocator
 * @brief High-performance memory allocation system
 * 
 * This group contains the memory allocator implementation featuring O(1) allocation,
 * SIMD-accelerated bin selection, and coroutine-based memory pressure handling.
 */

/**
 * @enum ak::internal::AllocState
 * @brief Allocation state enumeration
 * @ingroup Allocator
 * 
 * Represents the state of memory blocks in the allocator. The state encoding uses
 * bit patterns for efficient state checking:
 * - 0 -> invalid
 * - first bit -> is free
 * - second bit -> free 
 * - third bit -> sentinel
 * 
 * @var ak::internal::AllocState::INVALID
 * Invalid or uninitialized block state (0b0000)
 * 
 * @var ak::internal::AllocState::USED
 * Block is currently allocated to user (0b0010)
 * 
 * @var ak::internal::AllocState::FREE
 * Block is available for allocation (0b0001)
 * 
 * @var ak::internal::AllocState::WILD_BLOCK
 * Special large contiguous free region (0b0011)
 * 
 * @var ak::internal::AllocState::BEGIN_SENTINEL
 * Sentinel block at heap beginning (0b0100)
 * 
 * @var ak::internal::AllocState::LARGE_BLOCK_SENTINEL
 * Sentinel for large block management (0b0110)
 * 
 * @var ak::internal::AllocState::END_SENTINEL
 * Sentinel block at heap end (0b1100)
 */

/**
 * @struct ak::internal::AllocSizeRecord
 * @brief Compact size and state record for memory blocks
 * @ingroup Allocator
 * 
 * Efficiently packs block size and state information into a single 64-bit value.
 * This structure is used in block headers to minimize memory overhead.
 * 
 * @var ak::internal::AllocSizeRecord::size
 * Block size in bytes (48 bits, max ~281 TB)
 * 
 * @var ak::internal::AllocSizeRecord::state
 * Block state from AllocState enum (4 bits)
 * 
 * @var ak::internal::AllocSizeRecord::_reserved
 * Reserved bits for future use (12 bits)
 */

/**
 * @var ak::internal::ALLOC_STATE_IS_USED_MASK
 * @brief Bit mask for checking if block is in use
 * @ingroup Allocator
 */

/**
 * @var ak::internal::ALLOC_STATE_IS_FREE_MASK
 * @brief Bit mask for checking if block is free
 * @ingroup Allocator
 */

/**
 * @var ak::internal::ALLOC_STATE_IS_SENTINEL_MASK
 * @brief Bit mask for checking if block is a sentinel
 * @ingroup Allocator
 */

/**
 * @struct ak::internal::AllocHeader
 * @brief Basic allocation header for memory blocks
 * @ingroup Allocator
 * 
 * Minimal header structure containing size and state information for both
 * the current block and the previous block. This enables efficient 
 * bidirectional traversal and coalescing operations.
 * 
 * @var ak::internal::AllocHeader::thisSize
 * Size and state information for this block
 * 
 * @var ak::internal::AllocHeader::prevSize
 * Size and state information for the previous block
 */

/**
 * @struct ak::internal::FreeAllocHeader
 * @brief Extended header for free memory blocks
 * @ingroup Allocator
 * 
 * Extends AllocHeader with intrusive linked list pointers for free list
 * management. The list pointers are stored in the block's payload area,
 * providing O(1) insertion/removal without additional memory overhead.
 * 
 * @var ak::internal::FreeAllocHeader::thisSize
 * Size and state information for this block
 * 
 * @var ak::internal::FreeAllocHeader::prevSize
 * Size and state information for the previous block
 * 
 * @var ak::internal::FreeAllocHeader::freeListLink
 * Intrusive doubly-linked list node for free list management
 */

/**
 * @var ak::internal::ALLOCATOR_BIN_COUNT
 * @brief Number of segregated free list bins
 * @ingroup Allocator
 * 
 * The allocator uses 256 bins for fine-grained size segregation to minimize
 * fragmentation while maintaining O(1) bin selection performance.
 */

/**
 * @struct ak::internal::AllocStats
 * @brief Comprehensive allocation statistics
 * @ingroup Allocator
 * 
 * Tracks detailed per-bin statistics for performance analysis and optimization.
 * All counters are maintained in real-time during allocation operations.
 * 
 * @var ak::internal::AllocStats::binAllocCount
 * Number of allocation requests per bin (user-requested operations)
 * 
 * @var ak::internal::AllocStats::binReallocCount
 * Number of reallocation requests per bin (user-requested operations)
 * 
 * @var ak::internal::AllocStats::binFreeCount
 * Number of deallocation requests per bin (user-requested operations)
 * 
 * @var ak::internal::AllocStats::binSplitCount
 * Number of block split operations per bin (internal system operations)
 * 
 * @var ak::internal::AllocStats::binMergeCount
 * Number of block merge operations per bin (internal system operations)
 * 
 * @var ak::internal::AllocStats::binReuseCount
 * Number of exact-fit reuse operations per bin (internal system operations)
 * 
 * @var ak::internal::AllocStats::binPoolCount
 * Number of blocks added to free pool per bin (internal system operations)
 */

/**
 * @struct ak::internal::AllocTable
 * @brief Main data structure for the general purpose allocator
 * @ingroup Allocator
 * 
 * The AllocTable is the central control structure for a high-performance memory allocator
 * designed for single-threaded operation. It implements a segregated free list strategy 
 * with 256 bins for efficient memory allocation and deallocation.
 * 
 * ## Architecture Overview
 * 
 * The AllocTable serves as the central control structure for the allocator, managing:
 * - 256 segregated free list bins for different allocation sizes
 * - SIMD-optimized bin mask for fast free bin identification  
 * - Heap boundary tracking and memory usage statistics
 * - Sentinel blocks for safe memory traversal
 * - Performance counters for allocation profiling
 * 
 * ## Bin Organization (256 bins total)
 * 
 * 0 is an illegal allocation size. 
 * 
 * All "physical" allocations:
 *  - Have a header of 16 bytes
 *  - 16 bytes free lists are used to manage free blocks; therefore the minimum allocated payload will be of 32 bytes, given the header and free list requirements.
 *  - are aligned to 16-byte boundaries
 * 
 * Consider that the minimal "physical" allocation size is 32-bytes, therefore small allocations will
 * have a very high overhead.
 * 
 * It is recommended that the user builds pools for such objects; having small objects in the general purpose allocator is not a wise strategy 
 * as essentially the user is building a "vector with holes". For instance, by building a pool managed by bit fields 
 * the user can more effectively manage the memory as it has more constraints than a general purpose allocator.
 *
 * Nevertheless, the allocator is designed to be able to handle small allocations, but it is not optimized for it **by design**.
 *
 * The 256 bins are organized as follows:
 * 
 * - **Small bins (0-253)**: Fixed-size bins for common allocations
 *   
 *   - Bin 1: 1–16 bytes   (32 bytes of physical allocation)
 *   - Bin 2: 17–48 bytes  (64 bytes of physical allocation)
 *   - Bin 3: 49–80 bytes  (96 bytes of physical allocation)
 *   ...
 *   - Bin 253: 8,065–8,096 bytes (32 * 253 of physical allocation)
 *   - Bin 254: >= 8,097 bytes    (32 * 254 of physical allocation)
 *   - Bin 255: the wild block.
 * 
 * - **Medium bin (254)**: Variable-size bin for medium blocks (8,128+ bytes)
 *   Used for blocks too large for small bins but not requiring wild block allocation
 * 
 * - **Wild block bin (255)**: Special bin containing ONLY the wild block which is
 *   a large contiguous region used for very large allocations when no suitable
 *   free blocks exist in other bins
 * 
 * Essentially the allocator is designed to track 253 bins each growing by 32 bytes.
 * The medium bin is will use a first fit allocation strategy. 
 * 
 * ## SIMD-Accelerated Bin Selection
 * 
 * The allocator leverages AVX2 SIMD instructions for extremely fast bin selection.
 * - **Wild Block Guarantee**: Bit 255 (wild block) is always set to 1, ensuring
 *   that there's always at least one available bin for any allocation size.
 * 
 * -  **Branchless Performance**: This completely branchless implementation provides:
 * - O(1) bin selection regardless of allocation size or number of bins
 * - No conditional jumps or pipeline stalls
 * - Predictable execution time for all allocation sizes
 * - Optimal CPU pipeline utilization compared to O(n) linear search
 * 
 * ## Allocation Strategy
 * 
 * This allocator targets O(1) bin selection with a large number of bins to
 * reduce fragmentation, and it is designed to run safely under near
 * memory-exhaustion conditions:
 * 
 * - **O(1) bin selection with SIMD**: The target bin is determined in constant
 *   time using a single SIMD AND plus trailing-zero-count. The large number of
 *   bins (256) provides fine-grained size classes, minimizing internal
 *   fragmentation while keeping selection cost constant.
 * 
 * - **Coroutine-based allocations (co_await)**: Allocations are requested from
 *   within coroutines. If sufficient memory is available, allocation completes
 *   immediately. If not, the requesting coroutine suspends (via `co_await`) and
 *   is resumed automatically when memory becomes available. This avoids
 *   allocation failures while maintaining forward progress.
 * 
 * - **No external coordination structures**: The system avoids auxiliary queues
 *   or buffers that would require extra allocations. This eliminates "allocate to
 *   allocate" scenarios and reduces memory pressure precisely when memory is
 *   scarce.
 * 
 * - **Fixed-heap operation (initial design)**: The initial implementation assumes
 *   a fixed-size heap. Under pressure, operations do not fail; instead,
 *   coroutines naturally throttle by suspending until free memory is returned to
 *   the allocator.
 * 
 * Practical flow:
 *
 * 1. Compute target bin in O(1) with SIMD  
 * 2. If a suitable free block exists, allocate and return  
 * 3. Otherwise, suspend the coroutine; resume it when memory is freed  
 * 4. Coalescing on free improves availability and reduces fragmentation
 * 
 * ## Wild Block Strategy
 * 
 * The wild block serves as the allocator's "reservoir" for large allocations:
 * 
 * - **Purpose**: Handles allocations larger than 8,096 bytes or when no suitable
 *   free blocks exist in regular bins
 * - **Management**: Maintained as a single large contiguous region in bin 255
 * - **Splitting**: When used, the wild block is split and remainder stays as wild block
 * - **Coalescing**: Adjacent free blocks are merged back into the wild block when possible
 * - **Fragmentation Control**: Minimizes external fragmentation by providing a
 *   fallback for unusual allocation sizes
 * 
 * ## Free List Implementation
 * 
 * Each bin uses an intrusive doubly-linked list for optimal performance:
 * 
 * - **Storage**: List pointers stored in the free block's payload area (no overhead)
 * - **Structure**: Circular lists with sentinel heads for consistent operations
 * - **Performance**: O(1) insertion, removal, and empty checking
 * - **Cache Efficiency**: 64-byte alignment prevents false sharing between bins
 *
 * # Large blocks
 *
 * Large blocks are allocated are allocated past the  **large block sentinel** but before the **end block sentinel**
 * Large blocks do not have a header, but are managed using an external table.
 * Usually large blocks are allocated at the beginning of the software operation and stay allocated until the end.
 *
 * ## Wild block
 *
 * The wild block is a large contiguous region of memory that is used to allocate
 * large blocks.
 *
 * 
 * ## Thread Safety
 * 
 * **IMPORTANT**: This allocator is designed for single-threaded use only.
 * No synchronization primitives are used. For multi-threaded applications,
 * either use external locking or consider per-thread allocator instances.
 * 
 * ## Usage Example
 * 
 * Synchronous allocation with possible failure:
 *
 * ```cpp
 * // Initialize allocator with 1MB heap
 * AllocTable allocTable;
 * void* heap = mmap(nullptr, 1024*1024, PROT_READ|PROT_WRITE, 
 *                   MAP_PRIVATE|MAP_ANONYMOUS, -1, 0);
 * InitAllocTable(&allocTable, heap, 1024*1024);
 * 
 * // Allocate 128 bytes (goes to bin 3)
 * void* ptr = TryAllocMem(&allocTable, 128);
 * assert(ptr != nullptr);
 * // Free the allocation (triggers coalescing if possible)
 * FreeMem(&allocTable, ptr);
 * 
 * // Query statistics
 * printf("Allocations: %zu, Fragmentation: %.2f%%\n", 
 *        allocTable.totalAllocCount,
 *        (1.0 - (double)allocTable.freeMemSize / allocTable.memSize) * 100);
 * ```
 *
 * Coroutine-based allocation for systems that run close to memory exhaustion:
 *
 * ```cpp
 * DefineTask ProcessData() {
 *     void* buffer = co_await AllocMem(4096);  // Suspend if no memory
 *     // ... process data ...
 *     FreeAsync(buffer);  // May resume waiting coroutines
 * }
 * ```
 * 
 * ## Performance Characteristics
 * 
 * - **Allocation**: O(1) average case, O(log n) worst case for large allocations
 * - **Deallocation**: O(1) with immediate coalescing
 * - **Memory Overhead**: ~6.25% (16-byte headers on 32-byte aligned blocks)
 * - **Fragmentation**: Minimized through segregated bins and coalescing
 * - **Cache Performance**: Optimized with 64-byte alignments and SIMD operations
 * 
 * ## Statistics and Monitoring
 * 
 * The AllocTable provides comprehensive statistics for performance analysis:
 * 
 * ### Global Counters
 * - TODO: Outdated
 * - `totalAllocCount`: Track allocation frequency and patterns
 * - `totalFreeCount`: Monitor deallocation behavior and potential leaks
 * - `totalReallocCount`: Identify memory resize patterns
 * - `totalSplitCount`: Measure fragmentation from block splitting
 * - `totalMergeCount`: Track defragmentation effectiveness
 * - `totalReuseCount`: Monitor free list efficiency
 * 
 * ### Memory Usage Tracking
 * - `usedMemSize` / `freeMemSize`: Real-time memory utilization
 * - `memSize` vs `requestedMemSize`: Heap growth analysis
 * - `maxMemSize`: Memory limit enforcement
 * 
 * ### Per-Bin Statistics (via AllocStats)
 * - `binAllocCount[i]`: Allocation frequency per bin size
 * - `binFreeCount[i]`: Deallocation patterns per bin
 * - `binSplitCount[i]`: Fragmentation analysis per size class
 * - `binMergeCount[i]`: Coalescing effectiveness per bin
 * - `binReuseCount[i]`: Free list hit rate per bin
 * - `binPoolCount[i]`: Increased every time a block is inserted into the pool
 * 
 * ### Derived Metrics
 * ```cpp
 * // Memory utilization percentage
 * double utilization = (double)usedMemSize / memSize * 100;
 * 
 * // Average allocation size
 * double avgAllocSize = (double)usedMemSize / totalAllocCount;
 * 
 * // Fragmentation estimate (external)
 * double fragmentation = 1.0 - (largestFreeBlock / freeMemSize);
 * 
 * // Allocation/Free balance (should approach 1.0)
 * double balance = (double)totalFreeCount / totalAllocCount;
 * ```
 * 
 * ## Comparison with Other Single-Threaded Allocators
 * 
 * This allocator is optimized for constant-time bin selection, minimal
 * fragmentation, and robust behavior near memory exhaustion via coroutine
 * suspension (no external coordination structures).
 * 
 * - TLSF (Two-Level Segregated Fit):
 *   - Strengths: Deterministic O(1) alloc/free, good fragmentation profile.
 *   - Compared to this design: Similar asymptotics, but SIMD-based 256-bin
 *     selection here achieves lower instruction count on hot paths and finer
 *     size classes. Near OOM, TLSF must overprovision or fail; here, coroutines
 *     suspend without extra structures, avoiding "allocate to allocate".
 * 
 * - dlmalloc:
 *   - Strengths: Battle-tested, general-purpose.
 *   - Compared to this design: Typically higher bin lookup cost and more
 *     fragmentation. No built-in coroutine suspension model; requires
 *     overprovisioning or failure when memory is tight.
 * 
 * - jemalloc/tcmalloc (single-threaded use of a single arena):
 *   - Strengths: Excellent throughput and fragmentation in general-purpose use.
 *   - Compared to this design: Larger machinery, often tuned for multi-threaded
 *     workloads. This allocator's fixed-heap, SIMD O(1) selection and
 *     coroutine suspension provide more predictable latency and graceful
 *     behavior near OOM without extra coordination buffers.
 * 
 * - rpmalloc/mimalloc (single-threaded mode):
 *   - Strengths: Very fast small/medium-size alloc/free paths.
 *   - Compared to this design: Small-object fast paths typically rely on
 *     caches or slabs that require headroom. Under near-exhaustion, they can
 *     require overprovisioning to remain stable. Here, intentional omission of
 *     a growable small-object pool avoids extra memory pressure; the system
 *     instead throttles via coroutine suspension.
 * 
 * Key advantages of this near-OOM design:
 * - **No overprovisioning required**: The system remains operational by
 *   suspending requesters; memory pressure doesn't cascade into failures.
 * - **No external coordination allocations**: Wait semantics are intrinsic to
 *   coroutines, avoiding additional buffers/queues.
 * - **O(1) bin selection at scale**: 256 bins plus branchless SIMD yields
 *   constant-time selection with fine granularity to reduce fragmentation.
 * - **Fixed-heap predictability**: No OS calls in the hot path; latency is
 *   stable even under pressure.
 * 
 * ## Self-evaluated allocator Rating Card (x86-64, single-threaded)
 * 
 * - Throughput (steady-state, medium sizes): 9/10 — O(1) SIMD bin select + O(1) free/coalesce
 * - Tail Latency Predictability: 9/10 — Branchless hot path
 * - Near-OOM Robustness: 10/10 — Coroutine suspension; no overprovisioning required
 * - Internal Fragmentation: 8/10 — 256 bins, 32-byte granularity balance
 * - External Fragmentation: 8/10 — Immediate coalescing + wild block reservoir
 * - Memory Overhead: 8/10 — Compact headers; 32 byte minimum alloc size; 16 byte overhead
 * - Determinism (single-threaded): 9/10 — Fixed-heap, constant-time selection
 * - Portability: N/A by design — x86-64 AVX2/BMI1 focus
 * 
 * ## Possible Improvements
 * 
 * - SIMD lane selection micro-optimizations:
 *   - Use lane-zero tests with `_mm256_testz_si256` and BMI1 `tzcnt` per 64-bit lane,
 *     then combine via bitwise masks to remain branchless.
 *   - Optionally precompute 256 cut-masks (2 KB table) to avoid per-alloc shifts
 *     when targetBin frequency is high and predictable.
 * 
 * - TargetBin clamping and invariants:
 *   - Ensure targetBin is clamped to [0, 255] and bit 255 (wild block) stays set.
 *   - Add lightweight asserts to validate mask invariants in debug builds.
 * 
 * - Wait-list policies under pressure:
 *   - Introduce size-bucketed wait lists and/or aging to avoid starvation.
 *   - Batch wakeups on large frees/merges to reduce scheduler thrash.
 * 
 * - Large-block policy refinements (future OS-backed mode):
 *   - Page-align large blocks and track lifetime classes to reduce external fragmentation.
 *   - Consider `madvise`-style hints (when OS backing exists) for long-lived large blocks.
 * 
 * - Optional fixed small-object fast path (non-growable):
 *   - A compile-time-sized, non-growable slab carved at init can provide a fast path
 *     for 32–256 B objects without violating near-OOM goals; when exhausted, allocations
 *     naturally fall back to the general path and suspension semantics.
 * 
 * - Instrumentation and observability:
 *   - Add tracepoints for suspend/resume, split/merge, and wild-block usage.
 *   - Maintain short-term histograms for allocation sizes to guide tuning.
 *
 * ## FF Allocator vs Prior Art
 *
 * - Known ideas
 *   - O(1) binning (TLSF), boundary tags, wild/reservoir blocks: known.
 *   - Bitmaps for size classes: known; some allocators use bit twiddling, but SIMD-accelerated first-fit with 256 bins + branchless masks is not widely documented.
 *   - Sleepable allocations: common in kernels (e.g., Linux GFP_KERNEL can sleep; slab allocators wake sleepers), rare in general-purpose user-space allocators.
 * - Differentiators
 *   - Coroutine-native allocation that suspends under pressure (no external queues); "no allocate-to-allocate."
 *   - Fixed-heap operation tuned for near-OOM regimes with built-in backpressure.
 *   - Branchless, lane-wise SIMD (AVX2/BMI1) bin selection at 256 bins to reduce fragmentation while keeping O(1).
 * "Has anyone done this?"
 * - Closest parallels
 *   - Kernel allocators that may block on memory, then wake sleepers on free.
 *   - Research/industrial allocators with bitmap-based bin finding (some use popcnt/ctz), but few (if any) publicly emphasize SIMD+branchless selection at this granularity.
 *   - Task systems with memory-aware throttling/backpressure, but not at the allocator call boundary as an awaitable primitive.
 * - Likely novelty
 *   - The coroutine-suspending user-space allocator as a first-class API
 * - Contributions
 *   - O(1) branchless SIMD bin selection with 256 bins and a lane-wise first-set protocol.
 *   - Coroutine-native alloc API that suspends and resumes without external coordination or extra allocations.
 *   - Robust near‑OOM behavior: no overprovisioning; automatic backpressure; predictable tail latency.
 * - Evaluation (x86-64, single-threaded)
 *   - Throughput/latency vs TLSF, dlmalloc, mimalloc/rpmalloc (single arena), jemalloc/tcmalloc (single arena).
 *   - Fragmentation (internal/external), split/merge counts, largest-free vs total-free under adversarial and realistic traces.
 *   - Near‑OOM benchmarks: survival curves, request wait times, fairness, bursty free/wakeup behavior, tail latencies.
 *   - Ablations: with/without SIMD, with/without suspension, varying bin counts, wildcard reservoir on/off.
 * - Proofs/assurances
 *   - Correctness invariants (headers, coalescing, sentinels).
 *   - SIMD lane correctness and tzcnt fallbacks not required (x86-64 only, **by design**).
 *
 * @var ak::internal::AllocTable::freeListbinMask
 * SIMD bit mask for fast bin availability lookup.
 * 256-bit AVX2 register containing availability bits for all 256 bins.
 * Each bit indicates whether the corresponding bin contains free blocks.
 * Aligned to 64-byte boundary for optimal SIMD performance.
 * Used with SIMD instructions to find the first available bin in O(1) time.
 *
 * @var ak::internal::AllocTable::freeListBins
 * Array of doubly-linked list heads for each bin.
 * Each DLink serves as the head/sentinel for a bin's free block list.
 * Free blocks in each bin are organized as circular doubly-linked lists
 * for O(1) insertion and removal. Aligned to 64-byte boundary to prevent
 * false sharing and optimize cache performance when accessing multiple bins.
 *
 * @var ak::internal::AllocTable::freeListBinsCount
 * Size tracking for each bin's free blocks.
 * Contains the total size (in bytes) of all free blocks in each bin.
 * Used for statistics, fragmentation analysis, and allocation strategy
 * optimization. Aligned to 64-byte boundary for cache efficiency.
 *
 * @var ak::internal::AllocTable::heapBegin
 * Start of the raw heap memory region.
 * Points to the beginning of the heap as returned by the system allocator
 * (e.g., mmap, sbrk). May not be aligned to allocator requirements.
 * This is the address that must be passed to the system deallocator.
 *
 * @var ak::internal::AllocTable::heapEnd
 * End of the heap memory region.
 * Points to the first byte beyond the heap. The valid heap range is
 * [heapBegin, heapEnd). Used for bounds checking during allocation
 * and to determine when heap expansion is needed.
 *
 * @var ak::internal::AllocTable::memBegin
 * Start of aligned memory region for allocations.
 * Points to heapBegin aligned up to 32-byte boundary. All allocator
 * blocks are carved from the region [memBegin, memEnd). This ensures
 * all allocated blocks maintain proper 32-byte alignment.
 *
 * @var ak::internal::AllocTable::memEnd
 * End of aligned memory region for allocations.
 * Points to memBegin aligned up to 32-byte boundary. All allocator
 * blocks are carved from the region [memBegin, memEnd). This ensures
 * all allocated blocks maintain proper 32-byte alignment.
 *
 * @var ak::internal::AllocTable::memSize
 * Current total heap size.
 *
 * @var ak::internal::AllocTable::usedMemSize
 * Currently allocated memory.
 * Total bytes currently allocated to users (not including headers).
 * Updated on each allocation and deallocation for real-time tracking.
 *
 * @var ak::internal::AllocTable::freeMemSize
 * Currently free memory.
 * Total bytes available for allocation across all bins and wild block.
 * Should satisfy: usedMemSize + freeMemSize ≈ memSize (accounting for headers).
 *
 * @var ak::internal::AllocTable::maxFreeBlockSize
 * Maximum free block size.
 * The largest free block size in the heap.
 *
 * @var ak::internal::AllocTable::stats
 * Allocation statistics.
 * Comprehensive per-bin statistics for performance analysis.
 *
 * @var ak::internal::AllocTable::beginSentinel
 * Sentinel block at the beginning of heap.
 * Special marker block placed at memBegin that serves multiple purposes:
 * - **Boundary Protection**: Prevents backward traversal beyond heap start
 * - **Coalescing Simplification**: Eliminates special cases in merge logic
 * - **Traversal Safety**: Provides a consistent starting point for heap walks
 * - **Never Allocated**: Marked as permanently allocated to prevent use
 * 
 * The beginSentinel has zero payload size and is never included in free lists.
 *
 * @var ak::internal::AllocTable::wildBlock
 * Pointer to the wild block.
 * Points to the large contiguous free region used for allocations
 * that cannot be satisfied by regular bins. The wild block characteristics:
 * - **Dynamic Size**: Shrinks as allocations are carved from it
 * - **Fallback Allocation**: Used when no suitable bins are available
 * - **Coalescing Target**: Free blocks adjacent to wild block merge into it
 * - **Null When Fragmented**: May be null if heap is highly fragmented
 * - **Bin 255 Resident**: Always stored in the last bin when available
 *
 * @var ak::internal::AllocTable::largeBlockSentinel
 * Sentinel for large block tracking.
 * Special marker used to manage very large allocations (typically >64KB)
 * that bypass the normal binning system. Functions include:
 * - **Large Block Chain**: Links together oversized allocations
 * - **Direct Allocation Tracking**: Monitors blocks allocated directly from system
 * - **Heap Traversal Aid**: Helps navigate around large blocks during walks
 * - **Statistics Collection**: Enables separate accounting for large allocations
 *
 * @var ak::internal::AllocTable::endSentinel
 * Sentinel block at the end of heap.
 * Special marker block placed at heapEnd that provides heap boundary control:
 * - **Forward Traversal Limit**: Prevents walking beyond heap end
 * - **Coalescing Boundary**: Stops merge operations at heap edge
 * - **Growth Point**: Marks where heap expansion occurs
 * - **Consistency Check**: Validates heap structure during debugging
 * 
 * Like beginSentinel, this block is never allocated and has zero payload.
 */

/// \defgroup Task Task API
/// \brief Task API defines the API for creating and managing tasks.

/// \defgroup Kernel Kernel API
/// \brief Kernel API defines system level APIs.